---
layout: post
title: "The world is designed around white men. They share it with everyone else"
date: 2021-04-08T14:57:07.000Z
author: 经济学人en
from: https://www.economist.com/leaders/2021/04/10/the-world-is-designed-around-white-men-they-share-it-with-everyone-else
tags: [ 经济学人en ]
categories: [ 经济学人en ]
---
<!--1617893827000-->
[The world is designed around white men. They share it with everyone else](https://www.economist.com/leaders/2021/04/10/the-world-is-designed-around-white-men-they-share-it-with-everyone-else)
------

<div>
<img src="https://images.weserv.nl/?url=www.economist.com/img/b/1280/720/90/sites/default/files/images/print-edition/20210410_LDD002_0.jpg"/><div></div><aside ><div ><time itemscope="" itemType="http://schema.org/DateTime" dateTime="2021-04-10T00:00:00Z" >Apr 10th 2021</time><meta itemProp="author" content="The Economist"/></div><div ></div></aside><p data-caps="initial" ><span data-caps="initial">S</span><small>OME THINGS</small>, you might think, are obvious. For example, if you design a device which shines light through someone’s fingertip to measure the oxygen level of their blood, then the colour of the skin through which that light is shining should be a factor when the device is calibrated.</p><p >But no. Research suggests that, with honourable exceptions, <a href="https://www.economist.com/science-and-technology/2021/04/08/how-medicine-discriminates-against-non-white-people-and-women" data-tegid="f12c0an2qjlkjjv1uhea51d514ermcu9">pulse oximeters</a>, the machines which do this, overestimate oxygen levels three times more frequently (12% of the time) in people with black skin rather than white. When this informs decisions on whom to admit to hospital during a pandemic, more black than white patients are sent home on the mistaken conclusion that their blood-oxygen levels are within a safe range. This could have fatal consequences.</p><div id="" ><div><div id="econ-1"></div></div></div><p >The pulse oximeter is only the latest example of an approach to design which fails to recognise that human beings are different from one another. Other recent medical cases include an algorithm that gave white patients in America priority over those from racial minorities, and the discovery that implants such as prosthetic hips and cardiac pacemakers cause problems more often in women than in men.</p><p >Beyond medicine, there are many examples of this phenomenon in information technology: systems that recognise white faces but not black ones; legal software which recommends harsher sentences for black criminals than white; voice-activated programs that work better for men than women. Even mundane things like car seat-belts have often been designed with men in mind rather than women.</p><p >The origin of such design bias is understandable, if not forgivable. In the West, which is still the source of most innovation, engineers have tended to be white and male. So have medical researchers. That leads to groupthink, quite possibly unconscious, in both inputs and in outputs.</p><p >Input bias is particularly responsible for the <small>IT</small> cock-ups. Much of what is commonly called artificial intelligence is actually machine learning. As with any learning, the syllabus determines the outcome. Train software on white faces or men’s voices, and you will create a system that is focused on handling them well. More subtle biases are also in play, though. The faulty medical algorithm used prior medical spending as a proxy for current need. But black Americans spend less on health care than whites, so it discriminated against them. Sentencing software may similarly conflate poor social circumstances with the propensity to reoffend.</p><div id="" ><div><div id="econ-2"></div></div></div><p >Input bias is also a problem in medicine. Despite decades of rules on the matter, clinical trials are still overloaded with white men. As far as sex bias is concerned, trial designers do have half a point. If a female participant became pregnant and the treatment under test harmed her baby, that would be tragic. But there is no excuse for failing to make trials big enough to detect statistical differences between relevant groups.</p><p >Output bias is more intriguing. In a well-ordered market, competition should introduce diversity quite fast. In the past, women and non-white people may have lacked purchasing power, but that is surely no longer so. This, however, assumes that they are the customer when frequently they are not. Look to those who buy medical equipment, and you may see a mix that is more white and male than the population in hospital wards and doctors’ waiting rooms. Neither are face-recognition systems or sentencing software bought by those who suffer because of their failures.</p><p >Most consumer-led industries excel at generating choice by segmenting markets, so competition will probably sort things out. In other areas, though, boots may need to be applied to backsides. Regulators should, for example, factor in diversity when assessing clinical trials.</p><p >In both cases, however, it would behove firms to build diversity into their designs from the very outset. This means including women and non-white individuals in design teams. Eliminating design bias is not just about equality or doing the right thing, although all of these are important. It is also about creating products that meet the needs of women and the vast, non-white majority of the world’s population. It is one of those welcome areas where the best path is not just the right one, but often the profitable one, too. <span data-ornament="ufinish">■</span></p><p data-test-id="Footnote" >This article appeared in the Leaders section of the print edition under the headline &quot;Working in the dark&quot;</p>
</div>
