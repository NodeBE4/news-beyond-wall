---
layout: post
title: "A new book explains how social media promotes political polarisation"
date: 2021-03-29T16:27:03.000Z
author: 经济学人en
from: https://www.economist.com/united-states/2021/03/29/a-new-book-explains-how-social-media-promotes-political-polarisation
tags: [ 经济学人en ]
categories: [ 经济学人en ]
---
<!--1617035223000-->
[A new book explains how social media promotes political polarisation](https://www.economist.com/united-states/2021/03/29/a-new-book-explains-how-social-media-promotes-political-polarisation)
------

<div>
<img src="https://images.weserv.nl/?url=www.economist.com/img/b/1280/720/90/sites/default/files/images/2021/03/articles/main/20210327_usp504.jpg"/><div></div><aside ><div ><time itemscope="" itemType="http://schema.org/DateTime" dateTime="2021-03-29T00:00:00Z" >Mar 29th 2021</time><meta itemProp="author" content="The Economist"/></div><div ></div></aside><p >AMONG PEOPLE who worry about political polarisation, it has become an article of faith that breaking Americans out of their echo chambers is essential to returning the country to political health. But what if that assumption is wrong? That is the contrarian argument advanced by Chris Bail, a sociologist at Duke University, in a new book, “Breaking the Social Media Prism”. Mr Bail explains why exposure to different opinions often leads to ideological entrenchment rather than deliberation and compromise, and suggests that until people learn how to interact productively with their political opponents, it may be healthier for them and American democracy to remain in like-minded company.</p><p >In 2017 and 2018, Mr Bail and his colleagues at Duke’s Polarization Lab asked a random selection of 1,220 American Twitter users to follow one of two “bot” accounts that shared political posts. Users were assigned bots that shared posts from the opposing political party: a conservative might see messages from Planned Parenthood or Nancy Pelosi, for instance, while liberals might see Mitch McConnell or Fox News. Participants received one post every hour for a month. People were not told what the experiment measured; they were just paid $11 to follow the bot and received up to $18 in bonuses if they could recall what the account had tweeted.</p><div id="" ><div><div id="econ-1"></div></div></div><p >Before and after the study, researchers asked the people taking part their views on a range of topics, to determine whether the participants grew more politically moderate over the course of the experiment, as conventional wisdom would suggest. They found the opposite: Republicans shifted rightwards, while Democrats moved even further to the left.</p><p >The team subsequently conducted a second study that repeated the initial experiment but paired it with extended in-person interviews and online tracking. Researchers found that when echo chambers are breached, it is often by an extremist from the other side. Online, people encounter ad hominem attacks and provocative language more often than they do in real life. This prompts them to defend their political identities vigorously. Republicans grew more conservative because they resented, even felt threatened by, the rude liberals they came across online, and vice versa. Participants “came to realise that there was a war going on”, Mr Bail writes, “and [they] had to choose a side”.</p><p >One participant, Ray, photoshopped images of prominent Democrats onto pictures of human excrement. In real life, Mr Bail found Ray “polite and deferential” and reluctant to discuss politics or religion (a lesson Ray learned from his father). But once he logged onto Twitter, he changed. He told researchers that he trolled Democrats because he wanted to feel like part of a club. “Social media has amplified our ability to present alternative realities of ourselves,” says Mr Bail, and many choose more extreme versions.</p><p ><a href="https://www.economist.com/briefing/2020/10/22/social-medias-struggle-with-self-censorship">Social media</a> thus makes ordinary political partisanship performative and hostile, turning it from disagreement over policy to an insoluble battle of identities. Political extremists win plaudits for their finesse at “owning” the other side. As a result, moderates are often repulsed and disengaged from the platforms, sometimes leaving completely. Extremes attract those who remain.</p><div id="" ><div><div id="econ-2"></div></div></div><p >Mr Bail has a few proposals to counteract this toxic trend. First, users of social media should recognise that they are not seeing the world for what it is, but through a prism that enhances extremism and vitriol. The online public square has more shouters and stone-throwers, and fewer moderates and problem-solvers, than the real-life equivalent. Second, he encourages moderates to stay active on social media, in the hope that they can provide a steady stream of non-inflammatory argument. He also recommends that people engage calmly with opposing arguments and criticise members of their own party. Putting ideas before defending the “team” will make political identity less absolute.</p><p ><a href="https://www.economist.com/leaders/2020/10/22/how-to-deal-with-free-speech-on-social-media">Social-media platforms</a> could also take steps to depolarise their users, though whether they would do so—given that their business model centres on engagement, and extreme posts seem to promote it—is another question. In an ideal world, algorithms would promote rational debate and posts that bridge political divides rather than engagement through outrage. Instead of prioritising measures of social status, such as “likes” and “followers,” platforms could promote other metrics—perhaps a scoring system for bipartisan engagement. Mr Bail has developed his own social-media app, DiscussIt, which lets users talk politics anonymously with others from the opposing political party. It will never eclipse Facebook.</p><p >Ultimately, however, people are responsible for changing their own behaviour. “At some point,” Mr Bail argues, “we have to look in the mirror and ask, how are we, social-media users, contributing to this broader pattern?...We tend to think of people as simple dupes of technology and identity, that Facebook is just injecting us with this vitriol.” But the ample supply of vitriol comes from citizens, not social-media platforms. “We have to begin looking inward for the full answer.”</p>
</div>
