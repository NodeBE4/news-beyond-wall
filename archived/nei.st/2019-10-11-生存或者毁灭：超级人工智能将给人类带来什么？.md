---
layout: post
title: "生存或者毁灭：超级人工智能将给人类带来什么？"
date: 2019-10-11T09:58:22+01:00
author: Nei.st
from: https://nei.st/medium/southern/nfzm-1859e
tags: [ Nei.st ]
categories: [ Nei.st ]
---

<article class="post-6142 post type-post status-publish format-standard hentry category-southern" id="post-6142">
 <header class="page-header medium Archives">
  <div class="page-header__image">
  </div>
  <div class="page-header__content">
   <h1 class="page-title text-align-center">
    生存或者毁灭：超级人工智能将给人类带来什么？
   </h1>
  </div>
 </header>
 <div class="entry-content aesop-entry-content" id="post-6142-content">
  <link as="font" crossorigin="anonymous" href="//cdn.jsdelivr.net/gh/0nd1jyU39XQ/_/glyph/font-face/0uIzqoZjSuJfvSBnvgXTcApMtcVhMcpr.woff" rel="preload" type="font/woff"/>
  <link as="font" crossorigin="anonymous" href="//cdn.jsdelivr.net/gh/0nd1jyU39XQ/_/glyph/font-face/1sTnSLZWDKucPX6SAk.woff" rel="preload" type="font/woff"/>
  <p class="blog-post__description">
   结果表明，通用强化学习算法能够从一块白板出发，学会任何事物。AI 不需要依靠知识，也不需要来自人类的特定经验
  </p>
  <span id="more-6142">
  </span>
  <div class="container infzm">
   <div class="infzm-flex0">
    <a class="infzm __link-logo" dir="auto" href="https://nei.st/medium/southern-weekly">
    </a>
   </div>
  </div>
  <p>
   人工智能领域的科学家已经取得了一项惊人的成就。戴维·希尔弗 (David Silver) 是 DeepMind 团队的负责人，他和团队共同研发的
   <span class="markup--p">
    AlphaZero 从掌握初步规则开始，通过自己与自己对战，独立学会了国际象棋、围棋和将棋 (日本棋类游戏)。对于这三种棋类游戏，AlphaZero 已经超过了最好的人类棋手
   </span>
   。
  </p>
  <p>
   这一进步非常了不起。
   <span class="markup--p">
    1997 年，计算机深蓝 (Deep Blue) 打败了国际象棋世界冠军加里·卡斯帕罗夫 (Gary Kasparov)
   </span>
   ，它结合了优秀的算法与对棋局的出色理解。最好的人类棋手也贡献了关于开局、残局和局面评估的专业知识，从某种意义上来说，是人类将这些知识「教」给了程序。
  </p>
  <p>
   <span class="markup--p">
    而 AlphaZero 不同，不需要由人类专家向它传授自己掌握的知识。对于这样的棋类游戏，AI 可以独立学习，快速达到人类需要几个世纪才能累积的高度。AlphaZero 的研发人员表示：「无论对于国际象棋、将棋还是围棋， AlphaZero 使用的都是同样的算法，同样的网络结构。结果表明，通用强化学习算法 (即能够胜出的决策将被算法优先选择) 能够从一块白板出发，学会任何事物。它不需要依靠知识，也不需要来自人类的特定经验。」
   </span>
  </p>
  <p>
   随着人工智能快速发展，这个领域也开始面临越来越迫切的问题。研究人员、哲学家还有技术预言家纷纷开始辩论，设想未来可能出现的种种矛盾。
   <span class="markup--p">
    无论是感到期待还是恐慌，没有人会怀疑人工智能将主导我们的未来。这种主导作用也许是通过互联网，也许是与人类融合。
   </span>
  </p>
  <p>
   许多思想家都曾经深入思考过超级人工智能 (以及它对人类的态度)，试图以此预测未来的趋势。我们将探讨尼克·博斯特罗姆 (Nick Bostrom)、雷·库兹韦尔 (Ray Kurzweil)、本 (Ben) 和泰德·戈尔泽尔父子 (Ted Goertzel)、汉斯·莫拉维克 (Hans Moravec)、弗朗西斯·海利根 (Francis Heylighen)、雨果·德·加里斯 (Hugode Garis) 和克莱蒙·维达尔 (Clement Vidal) 的思考。
  </p>
  <div class="code-block code-block-1" style="margin: 8px 0; clear: both;">
   <div class="container ads_KbHEVhh8Rw">
    <div class="card card--blog post-sidebar">
     <div class="card-body">
      <div class="logo_ngcontent-kty-0">
      </div>
      <div class="iframe-blocker U6XAMK63Vh00WqvF2BacIQ">
       <div class="background-h60B">
       </div>
       <div class="WumZiPCS4MeMw4pxQ">
       </div>
      </div>
     </div>
     <div class="card-footer">
      <div class="card-footer-wrapper" layout="row bottom-left">
      </div>
     </div>
    </div>
   </div>
  </div>
  <p>
   <h2>
    评论的风口浪尖
   </h2>
  </p>
  <p>
   <span class="markup--p">
    当我们还不了解一件事物时，往往会作出夸张的设想，讨论它的性质时也会出现两极分化的观点。但是，正如剧作家拉辛 (Racine) 借他笔下人物所说，AI 无法承担我们过分施加的荣耀，也不至于因为它引发的忧虑而遭受羞辱。
   </span>
  </p>
  <p>
   尽管我们对 AI 取得的成就感到震惊，也意识到它可能会造成巨大的影响，但不能被狂热冲昏头脑。
   <span class="markup--p">
    AI 在许多高度专业化的任务中都取得了惊人的成绩，但它仍然难以胜任所有需要常识的任务，例如翻译文学作品。
   </span>
   自动驾驶也被寄予厚望，但是专家仍然保持谨慎，认为我们至少需要 50 年的时间，才可能制造出完全自主驾驶的汽车，让乘客能够安心在后排看书。
  </p>
  <p>
   在我撰写的专栏中，曾经提到过一些能够欺骗图片识别软件 (基于深度神经网络的算法) 的方法。比如，所有人都能一眼看出这是一门大炮的照片，算法却把它识别成了鸵鸟。
  </p>
  <p>
   虽然人工智能已经在越来越多的专业任务中取得了令人瞩目的成就，但它却面临两方面的障碍。首先，对于同样的任务，AI 获得结果的方式与人类的方式完全不同，它借助技术设备和计算，不需要人类介入。例如，部分自动驾驶汽车上装配的雷达和激光，它们计算和存储海量信息的能力远远超过人脑；另一方面，尽管取得了这样的成就，
   <span class="markup--p">
    AI 仍然无法将多种专业能力结合起来，形成一个自洽的、具备常识的系统
   </span>
   。我们无法合理地推测它们是否具备自我意识，拥有感知能力、幽默感，甚至是完备而稳定的「人格」。
  </p>
  <p>
   <h2>
    总是失误的预测
   </h2>
  </p>
  <div class="code-block code-block-1" style="margin: 8px 0; clear: both;">
   <div class="container ads_KbHEVhh8Rw">
    <div class="card card--blog post-sidebar">
     <div class="card-body">
      <div class="logo_ngcontent-kty-0">
      </div>
      <div class="iframe-blocker U6XAMK63Vh00WqvF2BacIQ">
       <div class="background-h60B">
       </div>
       <div class="WumZiPCS4MeMw4pxQ">
       </div>
      </div>
     </div>
     <div class="card-footer">
      <div class="card-footer-wrapper" layout="row bottom-left">
      </div>
     </div>
    </div>
   </div>
  </div>
  <p>
   1958 年，赫伯特·西蒙 (Herbert Simon，1978 年诺贝尔经济学奖得主) 宣称，在未来 10 年中，计算机将在国际象棋中打败人类冠军。他正确预言了我们将取得的成就，却弄错了等待的时间——他的预言过了 40 年才实现。
  </p>
  <p>
   1966 年，英国著名统计学家欧文·古德 (Irving Good) 为斯坦利·库布里克 (Stanley Kubrick) 的电影《2001 太空漫游》担任顾问，他设想在 2000 年将出现一个强大的人工智能，达到甚至超越人类的智力水平。现在的人工智能还没有达到这个水平，期待强大人工智能的人们只好推迟这个期限。谷歌工程技术总监库兹韦尔和奇点大学 (位于美国加州的一所私立学校) 联合创始人及董事长彼得·戴曼迪斯 (Peter Diamandis) 认为这个期限是 2030 年，而 AI 研究者泰德·戈尔泽尔和本·戈尔泽尔则认为要等到 2040 年，甚至 2100 年。
  </p>
  <p>
   这很可能会像国际象棋 AI 的发展一样：我们实现了目标，只是晚得多。因为这个问题非常困难，我们只有经过年复一年的努力才会实现这一点。如今，最合理的预测也许是不要作出任何预测！
  </p>
  <p>
   <span class="markup--p">
    对于必将到来的超级人工智能，人们提出了一个叫做「奇点」的概念，尽管谁也无法真正了解它究竟是什么。也许是某个日期，到时候地球上人工智能的能力曲线将以接近垂直的方式增长？也许是某个事件，机器毁灭人类，夺取了权力？也许是某一时刻，由于超越人类的人工智能带来了翻天覆地的变化，人类再也无法理解这个世界？
   </span>
  </p>
  <p>
   即便考虑著名的「摩尔定律」(计算设备的能力每 18 个月到 2 年就会翻倍，过去 50 年的发展基本符合这一定律)，「奇点」理论也不会很快成为严重的威胁。一方面，摩尔定律预测的增长是一个指数函数，它不会趋于直线；另一方面，在我们的物理世界中，所有的指数增长都会很快遇到阻碍，进而停滞不前。没有人认为摩尔定律会无限延续下去 (它已经遇到了困难)。最后，尽管计算和存储能力持续增长，也无法确保我们始终知道如何使用这些能力，创造出足以和我们对抗的通用型人工智能。
  </p>
  <p>
   对于谷歌、苹果、脸书、亚马逊和微软在这方面发出的宣言，我们应该审慎地看待。和这些技术公司的发言人相比，一些研究人员的态度要谨慎和清醒得多，例如法国国家科学研究中心 (CNRS) 伦理委员会主席、人工智能专家让-加布里埃尓·加纳西亚 (Jean-Gabriel Ganascia)。加纳西亚认为，那些人想要发起一个由企业主导、超越国界的大型项目，可能只是出于无尽的贪欲。奇点的概念被用来转移注意力、制造恐慌，但实际上这主要是为了劝阻其他人，并掩饰自己想要占据统治地位的野心。
  </p>
  <div class="code-block code-block-1" style="margin: 8px 0; clear: both;">
   <div class="container ads_KbHEVhh8Rw">
    <div class="card card--blog post-sidebar">
     <div class="card-body">
      <div class="logo_ngcontent-kty-0">
      </div>
      <div class="iframe-blocker U6XAMK63Vh00WqvF2BacIQ">
       <div class="background-h60B">
       </div>
       <div class="WumZiPCS4MeMw4pxQ">
       </div>
      </div>
     </div>
     <div class="card-footer">
      <div class="card-footer-wrapper" layout="row bottom-left">
      </div>
     </div>
    </div>
   </div>
  </div>
  <p>
   尽管无法确切地知道超级人工智能出现时是什么情形，但也无法阻止我们深入探讨、投下赌注。我们可以想象多个不同的场景，不设定具体期限，甚至考虑任何猜想都不正确。
  </p>
  <p>
   尼克·博斯特罗姆在他的书中定义了超级人工智能，并设定这种智能在任何一个方面都大大超过人类的认知能力。他还提出了两个截然不同的假设。
  </p>
  <p>
   (a) 基于硅的机器 (包括量子计算机) 进入实用领域并不断发展，最终这些人造设备在一切可能的智力活动中达到甚至超过人类水平，就像 AlphaZero 一样。而我们与它们的功能没有发生直接联系，也没有在肢体上与人工智能设备融合或相连接。
  </p>
  <p>
   (b) 基于生物性元素 (人类或其他的) 与信息技术设备结合的产物。简单地说，就是人类发明的高级技术与生物体有机地结合在了一起，他们之间是相互融合的。这种形式也有可能发展出超级人工智能。
  </p>
  <p>
   <h2>
    势力分化？
   </h2>
  </p>
  <p>
   研究人工智能的加里斯则将满足假设 (a) 的智慧生物称为「人工大脑」，并设想了一种基于这类技术的未来，我们将在下一部分讨论这种场景。
  </p>
  <div class="code-block code-block-1" style="margin: 8px 0; clear: both;">
   <div class="container ads_KbHEVhh8Rw">
    <div class="card card--blog post-sidebar">
     <div class="card-body">
      <div class="logo_ngcontent-kty-0">
      </div>
      <div class="iframe-blocker U6XAMK63Vh00WqvF2BacIQ">
       <div class="background-h60B">
       </div>
       <div class="WumZiPCS4MeMw4pxQ">
       </div>
      </div>
     </div>
     <div class="card-footer">
      <div class="card-footer-wrapper" layout="row bottom-left">
      </div>
     </div>
    </div>
   </div>
  </div>
  <p>
   而长久以来，科幻作品都采用了假设 (b)，并将这类结合了生物和信息技术，具备超级智能的混合体称为赛博格 (cyborgs，或改造人)。例如，假设为了弥补记忆局限，我们给自己插入容量高达到数太字节 (TB) 的芯片，从而能够直接在大脑中读取整部维基百科的信息。与此同时，借助一种能够通过可以瞬间读取的数学计算模块，我们能立刻回答「720 等于几」或「sin(cos(x)) 的五阶导数是什么」之类的问题。我们的智力将大幅提升。
  </p>
  <p>
   有时也会提到第三个假设：一台全球化的大脑，各地的机器通过网络交换信息，构成了某种去中心化、具有思想的存在。我们稍后再回到这个假设。
  </p>
  <p>
   <h2>
    悲观的加里斯
   </h2>
  </p>
  <p>
   加里斯认为：「社会将会分成三个哲学派别，派别之间将发生激烈的斗争。第一个派别由宇宙主义者构成，他们支持建造人工大脑；第二派别由地球主义者构成，他们反对建造人工大脑；而第三派别则支持赛博格，他们希望对大脑进行改造，从而把自己变成赛博格。」
  </p>
  <p>
   加里斯的著作《人工大脑之战》(The Artilect War) 介于科幻小说和严肃的未来学著作之间。在这部作品中，他认为三个派别之间的战争不可避免，并且在他看来，这场战争将比地球上发生过的任何战争都更惨烈，将在 21 世纪造成超过十亿人死亡。地球主义者在这场战争中获胜的希望非常渺茫，如果他们要取得胜利，就必须赶在另外两个可能结盟的派别察觉到威胁之前采取行动。在接受探索频道的访谈时，加里斯就曾表达过他的忧虑：「我很高兴能活在这个时代，我很有可能会平静地躺在自己的床上死去。但是我为我的孙辈感到担忧，他们可能被卷入人工大脑的战争，并且很可能因此丧命。」
  </p>
  <p>
   有趣的是，尽管超人类主义者在法国不受待见，加里斯也在书中对他们表达了谴责或嘲笑，但他们却非常乐观地捍卫自己的主张。超人类主义者认为应当毫无保留地发展增强技术，对人类进行改造——不能止步于眼镜、助听器和心脏起搏器，而是要采用一切可能的技术延长寿命、提升智力和强化身体机能。简而言之，他们支持赛博格的思想，属于赛博格主义者的阵营。他们将和宇宙主义者结盟，避免被地球主义者消灭。
  </p>
  <div class="code-block code-block-1" style="margin: 8px 0; clear: both;">
   <div class="container ads_KbHEVhh8Rw">
    <div class="card card--blog post-sidebar">
     <div class="card-body">
      <div class="logo_ngcontent-kty-0">
      </div>
      <div class="iframe-blocker U6XAMK63Vh00WqvF2BacIQ">
       <div class="background-h60B">
       </div>
       <div class="WumZiPCS4MeMw4pxQ">
       </div>
      </div>
     </div>
     <div class="card-footer">
      <div class="card-footer-wrapper" layout="row bottom-left">
      </div>
     </div>
    </div>
   </div>
  </div>
  <p>
   至于赛博格主义者和宇宙主义者之间会发生什么，超人类主义者和加里斯发生了分歧。大多数超人类主义者认为，人类赛博格将与具备超级智能的机械设备共存，不会发生生物学上的结合；而超人类主义者相信，将生物性元素 (特指他们自己) 和电子技术元素深度结合能够增强人类获得长生不死的能力，这才是人类未来的关键。
  </p>
  <p>
   加里斯的设想恰好相反：和人工大脑可能取得的成就相比，超人类主义简直无足轻重。在他看来，将生命体和未来的信息技术相融合只是一种幻想：人工大脑将对改造人这样的怪物不屑一顾，它只会毁灭改造人。
  </p>
  <p>
   而作为世界超人类主义者协会 (World Transhumanist Association) 联合创始人，博斯特罗姆也不认为人工大脑会对人类 (人工大脑的创造者，最终会成为赛博格) 采取和平友善的态度。他催促人们审视未来的智能产物，将它们视为一种威胁。博斯特罗姆的作品得到了埃隆·马斯克 (Elon Musk)、比尔·盖茨 (Bill Gates) 和李彦宏的推崇，这种看法似乎打动了他们，使他们开始传播恐慌信息 (也就是所谓的人工智能威胁论)。
  </p>
  <p>
   在加里斯看来，人工大脑 (具备意识的人工智能，或极其智能的机器) 不会友好地容忍人类甚至赛博格的存在，他说：「这个想法就像是尾巴摇狗一样，显然很荒谬。狗可比它的尾巴大得多，尾巴根本无法摇动狗。但超人类主义者认为人工大脑会和人类保持友好，这就犯了同样的逻辑错误……我认为这种观念是狂妄而天真的。它假设人类足够智能，即便面对一个能力超出人类几十亿倍的个体，也能正确判断它的动机。」
  </p>
  <p>
   <h2>
    其他可能
   </h2>
  </p>
  <p>
   加里斯忽略了另一种思潮：世界上所有的个体并不一定要互相竞争，而是相互连接，成为一种全球尺度的超级有机体。这种观点直接排除了「终结者之战」的可能。
  </p>
  <div class="code-block code-block-1" style="margin: 8px 0; clear: both;">
   <div class="container ads_KbHEVhh8Rw">
    <div class="card card--blog post-sidebar">
     <div class="card-body">
      <div class="logo_ngcontent-kty-0">
      </div>
      <div class="iframe-blocker U6XAMK63Vh00WqvF2BacIQ">
       <div class="background-h60B">
       </div>
       <div class="WumZiPCS4MeMw4pxQ">
       </div>
      </div>
     </div>
     <div class="card-footer">
      <div class="card-footer-wrapper" layout="row bottom-left">
      </div>
     </div>
    </div>
   </div>
  </div>
  <p>
   这种全球大融合的观点常常被认为是宗教性的。它存在于佛教的哲学中，也出现在天主教耶稣会哲学家德日进 (Pierre Teilhard de Chardin，1881–1955) 的思想中。德日进提出了「智慧圈」，这种「一体性的思想由人类的交流形成，覆盖了地球表面」。
  </p>
  <p>
   比利时哲学家弗朗西斯·海利根坚定地认为：超级人工智能将通过互联网传播，形成一个类似超级大脑的存在。他指出：「这个全球化的大脑将克服全球性超级有机体可能遭遇的挑战。它的能力将远远超过我们现有的水平，将具备某些神性的特质：无所不知 (知道我们的一切问题的答案)、无处不在 (存在于任何时间和地点)、无所不能 (能够以最高效的方式生产任何物品或服务)、博爱众生 (致力于为最多的人带来最大的幸福)。」
  </p>
  <p>
   比利时布鲁塞尔自由大学的哲学家克莱蒙·维达尔研究宇宙主义，他引用了威廉·斯塔福德 (William Stafford) 的诗句「所有的战争都有两个失败者」，指出暴力往往是非理性的。而斯蒂芬·平克 (Steven Pinker) 详细论述了世界会越来越和平，尽管我们觉得这个过程过于漫长，但它仍然是可被测量和解释的。一方面，无论我们是否愿意，所有人对所有人的相互依赖都使我们彼此产生联系。博弈论和对囚徒困境模型计算模拟的结果都支持这样的分析。这表明，合作才是多个社会和政治团体理性的选择。
  </p>
  <p>
   <h2>
    殊途同归
   </h2>
  </p>
  <p>
   「复杂性的伦理」是最后一个论据，可以证明「地球上不同动机的群体最终会结成一个利益共同体」的想法并不荒谬。如果按照这个伦理的预测，所有的智慧生物都会选择为一个普世价值共同体服务，将向着共同的目标行动，不再有发动战争的动机。
  </p>
  <p>
   尽管不同的讨论显示可能存在某种共同的方向，但这并不能保证当超级人工智能出现时 (如果它们会出现的话)，将与我们这些或多或少变成赛博格的人类和平结盟，并且在这个过程中没有任何一方试图消灭其他群体。在我看来，我们或许可以坚持一种极其简单的信念：并不是地球上生物性的躯体才具有人性，他们生产和制造的一切事物也应该有，甚至让这些事物得以存在的一切也有。地球在未来演化出的超级集合体会更加智能，内部之间的联系也越来越团结和紧密，尤其是在地球上刚刚出现的几个不同派别之间。这种讨论会永久避免加里斯设想的内部战争，因为战争变成了某种形式的自残甚至自杀行为。
  </p>
  <div class="code-block code-block-1" style="margin: 8px 0; clear: both;">
   <div class="container ads_KbHEVhh8Rw">
    <div class="card card--blog post-sidebar">
     <div class="card-body">
      <div class="logo_ngcontent-kty-0">
      </div>
      <div class="iframe-blocker U6XAMK63Vh00WqvF2BacIQ">
       <div class="background-h60B">
       </div>
       <div class="WumZiPCS4MeMw4pxQ">
       </div>
      </div>
     </div>
     <div class="card-footer">
      <div class="card-footer-wrapper" layout="row bottom-left">
      </div>
     </div>
    </div>
   </div>
  </div>
  <p>
   到这里我们已经超出了科幻小说的范畴。目前看来，我们要小心避免抨击任何对这个问题的思考，不要断言它们是愚蠢和不成熟的。AlphaZero 已经证明，我们能够借助机器取得不可思议的成就：人工智能再也不是一个遥远的梦。另一方面，物联网的快速发展将把全世界所有的参与者联系起来，构成一个致密的茧。毫无疑问，它将形成一个全新的结构，所有的事物都依赖于所有的因素。而我们就像我们的人工智能一样，不过是其中的组成部分。
  </p>
  <div class="container ag ah">
   <div class="fe n el">
    <a class="dt du bn bo bp bq br bs bt bu dv dw bx by dx dy" href="https://nei.st/medium/southern-weekly">
     <div class="c ff fg ag ah fh el fi fj ce fk fl fm fn fo fp fq fr fs ft fu">
      <div class="bs em en eo ep eq fv ah fw fg ag bm eu fx q fy fz p ac">
      </div>
     </div>
    </a>
   </div>
  </div>
 </div>
</article>
