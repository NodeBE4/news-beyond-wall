---
layout: post
title: "情绪识别: 中国AI读心术的惊悚黑科技"
date: 2021-02-03T00:47:57.000Z
author: 自由亚洲电台
from: https://www.rfa.org/mandarin/yataibaodao/renquanfazhi/rc-01252021120324.html
tags: [ 自由亚洲电台 ]
categories: [ 自由亚洲电台 ]
---
<!--1612313277000-->
[情绪识别: 中国AI读心术的惊悚黑科技](https://www.rfa.org/mandarin/yataibaodao/renquanfazhi/rc-01252021120324.html)
------

<div>
<p></p><p>摄像机多看你一眼，就能读懂你的心。这听起来有点惊悚，却是在中国越来越真实的现实。总部位于伦敦的国际人权机构<span>Article 19</span><span>最新报告发现，中国已广泛在维稳上应用情绪识别科技。然而，在缺乏国际标准与规范的情况下，中国取得数据后，做了什么研究？情绪识别这个中国媒体笔下的“黑科技”，又一次引发外界对中国人权恶化的担忧。</span><span></span></p><p><span>摄像机连上“阿尔法鹰眼系统”看你一眼，只要3<span>秒钟，</span>就能得出结论你是不是打算寻衅滋事或是有不法行为的可疑份子。</span></p><p><span>在中国媒体报道中，阿尔法鹰眼就这么厉害。从人们眨眼睛、耸肩到摸鼻子的小动作来做出判断。在</span><span>2014</span><span>年到</span><span>2015</span><span>年间，光是浙江义乌火车就通过这个堪称“人工智能</span><span>3.0</span><span>”的科技，逮捕了</span><span>153</span><span>个所谓的“犯罪分子”。</span></p><p><span>专研中国网络安全与政策的美国加州大学柏克莱分校博士生艾哈迈德（</span><span>Shazeda Ahmed</span><span>）梳理中国官方的公开文件与相关报导发现，多个省、市的地方公安机构和不同的情绪识别人工智能公司或安防行业合作。在中国，冰冷的人工智能科技，已经成为官方号称打击犯罪的利器。</span></p><p><span>“尤其对公安部门来说，情绪识别技术已经运用在三个方面：包括预警，也就是侦测可能犯罪、针对重点人口的监控与逮捕后的讯问过程。而所谓的‘重点人口’，包括刑满出狱的人，或是表达反对政府意见的抗议者，只要官方认定是会破坏稳定的人，这套情绪识别系统都会加强监控，目的是要确保这些重点人口不会出来反抗。”艾哈迈德接受本台专访时说。</span></p><p><br/></p><ul><li><span><a href="https://www.rfa.org/mandarin/yataibaodao/shaoshuminzu/bx-01142021094356.html"><strong>华为软件可识别维吾尔人 信息传至政府</strong></a></span></li><li><strong><a href="https://www.rfa.org/mandarin/yataibaodao/shaoshuminzu/pl-12172020134246.html">阿里巴巴开发维吾尔人面部识别工具</a></strong></li><li><strong><a href="https://www.rfa.org/mandarin/Xinwen/2-03092020120053.html">中国监控技术升级 “口罩人脸识别”横空出世</a></strong></li></ul><p><br/></p><p><strong><span>监控加识读</span></strong> <strong>官方维稳预警执法上演“</strong><strong><span>1984”</span></strong><strong><span>？</span></strong></p><p><span>中国无处不在的摄像机搜集公共场所出没人群的脸部资讯，而老大哥不只看你，还要读你。想像一下站在天安门广场上一脸微笑、精神饱满的高喊着“爱国爱党”的人们，情绪识别技术还能分析喊口号的群众是否真心，仿佛重现乔治·奥威尔《</span><span>1984</span><span>》的小说情节。</span></p><p><span>曾在北京生活的艾哈迈德说，她感到震惊的是，在中国，不只是公安机关可以使用这些数据。</span></p><p><span>报告中提到，除了新疆维吾尔人一直是中国官方重点监测的人口外，</span><span>2019</span><span>年，中国《四川警察学院学报》也提到，要研究将“微表情识别技术”应用在入藏公路的安全强化上。打着科技执法大旗的这些做法，引发外界对人权的担忧。</span></p><p><span>“不只是人脸识别，中国的相关企业还综合声音、心跳等信号，发展整合出多模式的情绪识别技术。但人类的情绪有时是复杂的，这些变数都可能会让准确系数降低。这对执法有正面的帮助吗？”她忧心地说。</span></p><p><span>中国情绪识别科技十大企业有综合声音与肢体的“整合多模式情感识别技术”。报告预估，这个潜在市场规模超过</span><span>146</span><span>亿美元。艾哈迈德认为，中国技术可能借助一带一路走出去，而东南亚国家是潜在市场。</span></p><p><strong><span>科技举报</span></strong> <strong>数字化的枫桥经验</strong></p><p><span>这份名为《情绪纠结》的报告特别针对中国的市场与应用研究。除了提出浙江宁波的阿尔法鹰眼在中国的网格式公安监控系统“雪亮工程”扮演重要角色外，还有像是深圳的科思创动、北京翼开科技、杭州中威电子、秒懂情绪识别技术、睿数科技、深圳安视宝、太古计算、云思创智与力维等，都在不同省市的机场、海关、高铁站等公共场所承担维稳大责，成为中国安保行业的领头羊。</span></p><p><span>艾哈迈德形容，这是重现毛泽东时期的“枫桥经验”。然而，在数字时代，举报的不是街坊邻里大妈，而是拥有情绪识别技术的摄影机与软件。</span></p><p><span><span>艾哈迈德和</span>报告的另一位作者、</span><span>Article 19</span><span>资深研究员玛达（</span><span>Vidushi Marda</span><span>）都强调，探讨人工智能应用对社会发展的影响时，不是说所有问题都是中国造成的，但整个人类社会面临新科技日新月异的挑战，国际规范却缺位，而中国这样一个的庞大市场超速发展，他们拥有的数据库越大，经由演算后情绪识别技术就会越成熟。这对所有人都是警示。他们认为，一些基本的道德原则不该改变。</span></p><p><strong><span>中国情绪识别科技的弯道超速</span></strong></p><p><span>“关键还是在透明度，包括如何取得数据、如何应用数据的知情权。现有的情绪识别科技最终可能还是会应用在日常生活中，但我们要有什么样的国际规则？在现有国际法精神下，包括言论自由、隐私权与反种族歧视，我认为，这些基本原则目前就已经适用在情绪识别科技上了。”玛达说。</span></p><p><span>事实上，情绪识别的概念与想法并不源自中国。马达告诉本台，在数字科技并不发达的</span><span>1960</span><span>年代，美国心理学家艾克曼（</span><span>Paul Ekman</span><span>）就研究通过人的脸部细微表情，来辨识是否撒谎。他的理论确实也应用在美国联邦调查局后来的犯罪侦查上。</span></p><p><span>“真相都写在脸上。”</span><span> 2009</span><span>年当时红极一时的美国电视剧《别对我撒谎》（</span><span>Lie to Me</span><span>）主角莱特曼博士的这句经典台词，就是根据艾克曼的真实故事改编，当年在中国网络上也是热门影集。几乎在同一时间，世界也开始人工智能科技的应用发展，手机的人脸辨识可说是生物识别技术的里程碑，原本的用意是为了加强安全性。</span></p><p><span>然而，在最近这五<span>年，</span>中国犹如加速超车，让冰冷的摄像头，变成一个又一个的莱特曼。但科技是更保护人性还是毁灭人性？端看政府存乎一心，中国的近邻印度有实例。</span></p><p><span>马达举例，“向中国输出情绪识别技术的是一家荷兰公司，中国这个市场渴望有这样的技术发展，这一点都不难想像。但我想说，像我生活的印度，印度警方最近要把情绪识别技术应用在公共场所，来防范女性受暴力侵害。”</span></p><p><span>她说，国际规则的制订涉及两大国际电信组织，包括国际电信联盟（</span><span>International Telecommunications Union</span><span>），中国是非常积极的成员；另一个是电气与电子工程师协会（</span><span>Institute of Electrical and Electronics Engineers, IEEE</span><span>）。专研人工智能科技应用相关法律的马达也是联合国人工智能发展专家组的成员之一。她在报告中建议国际社会，应该禁止情绪识别科技的继续发展、销售与进出口，因为这与现有的国际人权基本原则不符；她还建议中国政府，也应禁止情绪识别技术的持续发展、销售与转移，并尽快制订相应的法律，让受情绪识别科技影响的个人有救济机制。</span></p><p><span>真相并不一定都写在脸上。马达认为，长此发展下去，如果没有完善相应的规范措施，人们可能在改变不了监控的环境下，改变自己表达情绪的方式，这会是个令人惊恐的发展。</span></p><p><br/></p><p><span><span>自由亚洲电台记者郑崇生华盛顿报道   责编：申铧   网编：洪伟<br/></span></span></p>
</div>
